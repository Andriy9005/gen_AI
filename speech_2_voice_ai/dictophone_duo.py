import os
import sounddevice as sd
from scipy.io.wavfile import write
import whisper
import pandas as pd
from jiwer import wer
import language_tool_python
import time

# ğŸ“ Ğ”Ğ¾Ğ´Ğ°Ñ‚Ğ¸ ffmpeg Ğ´Ğ¾ ÑˆĞ»ÑÑ…Ñƒ (ÑĞºÑ‰Ğ¾ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ¾)
ffmpeg_path = r"C:\Users\Andriy.Bespalyy\ffmpeg\bin"
os.environ["PATH"] = ffmpeg_path + os.pathsep + os.environ["PATH"]

# ğŸ™ï¸ ĞĞ°Ğ»Ğ°ÑˆÑ‚ÑƒĞ²Ğ°Ğ½Ğ½Ñ Ğ°ÑƒĞ´Ñ–Ğ¾
duration = 10
sample_rate = 44100
device_index = 8
output_file = "mic_recording.wav"

print(f"ğŸ¤ Recording for {duration} seconds from device #{device_index}...")
recording = sd.rec(
    int(duration * sample_rate),
    samplerate=sample_rate,
    channels=1,
    dtype='int16',
    device=device_index
)
sd.wait()
write(output_file, sample_rate, recording)
print(f"âœ… Audio saved as {output_file}")

# ğŸ§ Ğ’Ñ–Ğ´Ñ‚Ğ²Ğ¾Ñ€ĞµĞ½Ğ½Ñ
sd.play(recording, samplerate=sample_rate)
sd.wait()

# ğŸ§  Ğ—Ğ°Ğ²Ğ°Ğ½Ñ‚Ğ°Ğ¶ĞµĞ½Ğ½Ñ Ğ¼Ğ¾Ğ´ĞµĞ»Ñ– Whisper
model = whisper.load_model("medium")

# ğŸ§  Ğ’Ğ¸Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ½Ñ Ğ¼Ğ¾Ğ²Ğ¸ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡Ğ½Ğ¾
print("ğŸ§  Detecting language...")
lang_result = model.transcribe(output_file, task="transcribe", language=None)
detected_lang = lang_result["language"]
print(f"ğŸŒ Detected language: {detected_lang}")

# ĞŸÑ–Ğ´ĞºĞ»ÑÑ‡Ğ°Ñ”Ğ¼Ğ¾ Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ğ¸Ğ¹ LanguageTool
if detected_lang == "uk":
    tool = language_tool_python.LanguageToolPublicAPI('uk-UA')
elif detected_lang == "en":
    tool = language_tool_python.LanguageToolPublicAPI('en-US')
else:
    print(f"âš ï¸ Unsupported language: {detected_lang}. Skipping grammar correction.")
    tool = None

# âœï¸ Ğ¤Ñ–Ğ½Ğ°Ğ»ÑŒĞ½Ğ° Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ¿Ñ†Ñ–Ñ Ğ· Ğ²Ñ–Ğ´Ğ¾Ğ¼Ğ¾Ñ Ğ¼Ğ¾Ğ²Ğ¾Ñ
print("ğŸ“ Transcribing...")
result = model.transcribe(output_file, language=detected_lang)
raw_text = result["text"]

# ğŸ›  Ğ“Ñ€Ğ°Ğ¼Ğ°Ñ‚Ğ¸Ñ‡Ğ½Ğ° ĞºĞ¾Ñ€ĞµĞºÑ†Ñ–Ñ
def correct_text(text):
    if tool is None:
        return text
    matches = tool.check(text)
    return language_tool_python.utils.correct(text, matches)

corrected = correct_text(raw_text)
print(f"âœ… Corrected transcript:\n{corrected}")

# ğŸ’¾ Ğ—Ğ±ĞµÑ€ĞµĞ¶ĞµĞ½Ğ½Ñ Ğ² CSV
transcripts = [{"file": output_file, "transcript": corrected}]
df = pd.DataFrame(transcripts)
df.to_csv("transcriptions_corrected.csv", index=False, encoding="utf-8-sig")
print("ğŸ“„ Saved to transcriptions_corrected.csv")

# ğŸ“ WER (ÑĞºÑ‰Ğ¾ ground-truth Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ¸Ğ¹)
ground_truths = {
    "mic_recording.wav": "ĞÑ‡Ñ–ĞºÑƒĞ²Ğ°Ğ½Ğ¸Ğ¹ Ñ‚ĞµĞºÑÑ‚ Ñ‚ÑƒÑ‚ Ğ´Ğ»Ñ Ğ¾Ñ†Ñ–Ğ½ĞºĞ¸ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚Ñ–"  # Ğ°Ğ±Ğ¾ Ğ°Ğ½Ğ³Ğ»Ñ–Ğ¹ÑÑŒĞºĞ¸Ğ¹, ÑĞºÑ‰Ğ¾ Ğ°ÑƒĞ´Ñ–Ğ¾ Ğ±ÑƒĞ»Ğ¾ Ğ°Ğ½Ğ³Ğ»Ñ–Ğ¹ÑÑŒĞºĞ¾Ñ
}

wer_scores = []
if output_file in ground_truths:
    gt = ground_truths[output_file]
    print(f"ğŸ” Ground truth: {gt}")
    print(f"ğŸ“ Predicted   : {corrected}")
    error = wer(gt, corrected)
    wer_scores.append({"file": output_file, "WER": error})
    df_wer = pd.DataFrame(wer_scores)
    df_wer.to_csv("wer_scores.csv", index=False, encoding="utf-8-sig")
    print(f"ğŸ“‰ WER saved: {error:.2%}")
else:
    print("â„¹ï¸ Ground-truth not provided â†’ WER not calculated.")
